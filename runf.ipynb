{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "411475d1-d96e-413f-bb3e-dd6e2ed3ef90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 32, 32, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 16, 16, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 8, 8, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 8, 8, 128)         73856     \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 8, 8, 128)         147584    \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPoolin  (None, 4, 4, 128)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1024)              2098176   \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 512)               524800    \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2915114 (11.12 MB)\n",
      "Trainable params: 2915114 (11.12 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/120\n",
      "782/782 [==============================] - 123s 157ms/step - loss: 1.9062 - accuracy: 0.2900 - val_loss: 1.6440 - val_accuracy: 0.3979\n",
      "Epoch 2/120\n",
      "782/782 [==============================] - 123s 158ms/step - loss: 1.4922 - accuracy: 0.4542 - val_loss: 1.3917 - val_accuracy: 0.4903\n",
      "Epoch 3/120\n",
      "782/782 [==============================] - 125s 160ms/step - loss: 1.2849 - accuracy: 0.5349 - val_loss: 1.1330 - val_accuracy: 0.5925\n",
      "Epoch 4/120\n",
      "782/782 [==============================] - 131s 168ms/step - loss: 1.1227 - accuracy: 0.5995 - val_loss: 1.1717 - val_accuracy: 0.5826\n",
      "Epoch 5/120\n",
      "782/782 [==============================] - 136s 174ms/step - loss: 1.0034 - accuracy: 0.6429 - val_loss: 0.9119 - val_accuracy: 0.6845\n",
      "Epoch 6/120\n",
      "782/782 [==============================] - 135s 172ms/step - loss: 0.8946 - accuracy: 0.6825 - val_loss: 0.8246 - val_accuracy: 0.7103\n",
      "Epoch 7/120\n",
      "782/782 [==============================] - 126s 161ms/step - loss: 0.8153 - accuracy: 0.7106 - val_loss: 0.7995 - val_accuracy: 0.7203\n",
      "Epoch 8/120\n",
      "782/782 [==============================] - 125s 160ms/step - loss: 0.7390 - accuracy: 0.7391 - val_loss: 0.7256 - val_accuracy: 0.7446\n",
      "Epoch 9/120\n",
      "782/782 [==============================] - 126s 161ms/step - loss: 0.6795 - accuracy: 0.7606 - val_loss: 0.7093 - val_accuracy: 0.7582\n",
      "Epoch 10/120\n",
      "782/782 [==============================] - 126s 161ms/step - loss: 0.6260 - accuracy: 0.7798 - val_loss: 0.6777 - val_accuracy: 0.7676\n",
      "Epoch 11/120\n",
      "782/782 [==============================] - 125s 160ms/step - loss: 0.5765 - accuracy: 0.7993 - val_loss: 0.6575 - val_accuracy: 0.7734\n",
      "Epoch 12/120\n",
      "782/782 [==============================] - 125s 160ms/step - loss: 0.5381 - accuracy: 0.8089 - val_loss: 0.6361 - val_accuracy: 0.7826\n",
      "Epoch 13/120\n",
      "782/782 [==============================] - 126s 161ms/step - loss: 0.4994 - accuracy: 0.8250 - val_loss: 0.6202 - val_accuracy: 0.7910\n",
      "Epoch 14/120\n",
      "782/782 [==============================] - 126s 162ms/step - loss: 0.4710 - accuracy: 0.8346 - val_loss: 0.6176 - val_accuracy: 0.7937\n",
      "Epoch 15/120\n",
      "782/782 [==============================] - 126s 161ms/step - loss: 0.4350 - accuracy: 0.8463 - val_loss: 0.6338 - val_accuracy: 0.7895\n",
      "Epoch 16/120\n",
      "782/782 [==============================] - 126s 161ms/step - loss: 0.4045 - accuracy: 0.8568 - val_loss: 0.6098 - val_accuracy: 0.7969\n",
      "Epoch 17/120\n",
      "782/782 [==============================] - 126s 162ms/step - loss: 0.3751 - accuracy: 0.8668 - val_loss: 0.6174 - val_accuracy: 0.7992\n",
      "Epoch 18/120\n",
      "782/782 [==============================] - 126s 161ms/step - loss: 0.3572 - accuracy: 0.8731 - val_loss: 0.6231 - val_accuracy: 0.7998\n",
      "Epoch 19/120\n",
      "782/782 [==============================] - 127s 162ms/step - loss: 0.3251 - accuracy: 0.8843 - val_loss: 0.5945 - val_accuracy: 0.8064\n",
      "Epoch 20/120\n",
      "782/782 [==============================] - 127s 162ms/step - loss: 0.3109 - accuracy: 0.8881 - val_loss: 0.6395 - val_accuracy: 0.8015\n",
      "Epoch 21/120\n",
      "782/782 [==============================] - 126s 161ms/step - loss: 0.2950 - accuracy: 0.8953 - val_loss: 0.6219 - val_accuracy: 0.8044\n",
      "Epoch 22/120\n",
      "782/782 [==============================] - 126s 161ms/step - loss: 0.2702 - accuracy: 0.9033 - val_loss: 0.6368 - val_accuracy: 0.8065\n",
      "Epoch 23/120\n",
      "782/782 [==============================] - 125s 159ms/step - loss: 0.2530 - accuracy: 0.9092 - val_loss: 0.6472 - val_accuracy: 0.8035\n",
      "Epoch 24/120\n",
      "782/782 [==============================] - 125s 159ms/step - loss: 0.2365 - accuracy: 0.9152 - val_loss: 0.6294 - val_accuracy: 0.8079\n",
      "Epoch 25/120\n",
      "782/782 [==============================] - 125s 160ms/step - loss: 0.2252 - accuracy: 0.9209 - val_loss: 0.6430 - val_accuracy: 0.8091\n",
      "Epoch 26/120\n",
      "782/782 [==============================] - 125s 160ms/step - loss: 0.2120 - accuracy: 0.9236 - val_loss: 0.6383 - val_accuracy: 0.8059\n",
      "Epoch 27/120\n",
      "782/782 [==============================] - 125s 160ms/step - loss: 0.1996 - accuracy: 0.9288 - val_loss: 0.6986 - val_accuracy: 0.8010\n",
      "Epoch 28/120\n",
      "782/782 [==============================] - 125s 160ms/step - loss: 0.1892 - accuracy: 0.9308 - val_loss: 0.6735 - val_accuracy: 0.8172\n",
      "Epoch 29/120\n",
      "782/782 [==============================] - 125s 160ms/step - loss: 0.1735 - accuracy: 0.9392 - val_loss: 0.6713 - val_accuracy: 0.8092\n",
      "Epoch 30/120\n",
      "782/782 [==============================] - 125s 160ms/step - loss: 0.1602 - accuracy: 0.9429 - val_loss: 0.6855 - val_accuracy: 0.8100\n",
      "Epoch 31/120\n",
      "782/782 [==============================] - 125s 160ms/step - loss: 0.1540 - accuracy: 0.9461 - val_loss: 0.6886 - val_accuracy: 0.8151\n",
      "Epoch 32/120\n",
      "782/782 [==============================] - 125s 160ms/step - loss: 0.1464 - accuracy: 0.9483 - val_loss: 0.6773 - val_accuracy: 0.8133\n",
      "Epoch 33/120\n",
      "782/782 [==============================] - 125s 159ms/step - loss: 0.1400 - accuracy: 0.9503 - val_loss: 0.7144 - val_accuracy: 0.8128\n",
      "Epoch 34/120\n",
      "782/782 [==============================] - 125s 160ms/step - loss: 0.1332 - accuracy: 0.9523 - val_loss: 0.7328 - val_accuracy: 0.8097\n",
      "Epoch 35/120\n",
      "782/782 [==============================] - 125s 159ms/step - loss: 0.1282 - accuracy: 0.9554 - val_loss: 0.6991 - val_accuracy: 0.8130\n",
      "Epoch 36/120\n",
      "782/782 [==============================] - 126s 161ms/step - loss: 0.1233 - accuracy: 0.9566 - val_loss: 0.7045 - val_accuracy: 0.8163\n",
      "Epoch 37/120\n",
      "782/782 [==============================] - 125s 160ms/step - loss: 0.1158 - accuracy: 0.9601 - val_loss: 0.7157 - val_accuracy: 0.8198\n",
      "Epoch 38/120\n",
      "782/782 [==============================] - 125s 160ms/step - loss: 0.1119 - accuracy: 0.9611 - val_loss: 0.7461 - val_accuracy: 0.8188\n",
      "Epoch 39/120\n",
      "782/782 [==============================] - 126s 161ms/step - loss: 0.1090 - accuracy: 0.9610 - val_loss: 0.7087 - val_accuracy: 0.8149\n",
      "Epoch 40/120\n",
      "782/782 [==============================] - 125s 160ms/step - loss: 0.1042 - accuracy: 0.9638 - val_loss: 0.7167 - val_accuracy: 0.8154\n",
      "Epoch 41/120\n",
      "782/782 [==============================] - 125s 160ms/step - loss: 0.0979 - accuracy: 0.9656 - val_loss: 0.7230 - val_accuracy: 0.8199\n",
      "Epoch 42/120\n",
      "782/782 [==============================] - 125s 160ms/step - loss: 0.0936 - accuracy: 0.9675 - val_loss: 0.7722 - val_accuracy: 0.8159\n",
      "Epoch 43/120\n",
      "782/782 [==============================] - 125s 160ms/step - loss: 0.0934 - accuracy: 0.9669 - val_loss: 0.7538 - val_accuracy: 0.8188\n",
      "Epoch 44/120\n",
      "782/782 [==============================] - 126s 161ms/step - loss: 0.0870 - accuracy: 0.9688 - val_loss: 0.7817 - val_accuracy: 0.8190\n",
      "Epoch 45/120\n",
      "782/782 [==============================] - 125s 160ms/step - loss: 0.0865 - accuracy: 0.9697 - val_loss: 0.7666 - val_accuracy: 0.8150\n",
      "Epoch 46/120\n",
      "782/782 [==============================] - 125s 160ms/step - loss: 0.0839 - accuracy: 0.9698 - val_loss: 0.7816 - val_accuracy: 0.8153\n",
      "Epoch 47/120\n",
      "782/782 [==============================] - 124s 159ms/step - loss: 0.0801 - accuracy: 0.9714 - val_loss: 0.7842 - val_accuracy: 0.8177\n",
      "Epoch 48/120\n",
      "782/782 [==============================] - 125s 159ms/step - loss: 0.0766 - accuracy: 0.9738 - val_loss: 0.7813 - val_accuracy: 0.8173\n",
      "Epoch 49/120\n",
      "782/782 [==============================] - 125s 159ms/step - loss: 0.0748 - accuracy: 0.9739 - val_loss: 0.7995 - val_accuracy: 0.8180\n",
      "Epoch 50/120\n",
      "782/782 [==============================] - 125s 159ms/step - loss: 0.0719 - accuracy: 0.9748 - val_loss: 0.7667 - val_accuracy: 0.8175\n",
      "Epoch 51/120\n",
      "782/782 [==============================] - 125s 160ms/step - loss: 0.0704 - accuracy: 0.9744 - val_loss: 0.8125 - val_accuracy: 0.8175\n",
      "Epoch 52/120\n",
      "782/782 [==============================] - 125s 159ms/step - loss: 0.0654 - accuracy: 0.9773 - val_loss: 0.8031 - val_accuracy: 0.8183\n",
      "Epoch 53/120\n",
      "782/782 [==============================] - 125s 160ms/step - loss: 0.0658 - accuracy: 0.9772 - val_loss: 0.7993 - val_accuracy: 0.8221\n",
      "Epoch 54/120\n",
      "782/782 [==============================] - 127s 163ms/step - loss: 0.0661 - accuracy: 0.9771 - val_loss: 0.7966 - val_accuracy: 0.8203\n",
      "Epoch 55/120\n",
      "782/782 [==============================] - 125s 160ms/step - loss: 0.0594 - accuracy: 0.9792 - val_loss: 0.8199 - val_accuracy: 0.8193\n",
      "Epoch 56/120\n",
      "782/782 [==============================] - 125s 160ms/step - loss: 0.0583 - accuracy: 0.9798 - val_loss: 0.8129 - val_accuracy: 0.8186\n",
      "Epoch 57/120\n",
      "782/782 [==============================] - 125s 159ms/step - loss: 0.0573 - accuracy: 0.9805 - val_loss: 0.8094 - val_accuracy: 0.8178\n",
      "Epoch 58/120\n",
      "782/782 [==============================] - 125s 160ms/step - loss: 0.0559 - accuracy: 0.9812 - val_loss: 0.8034 - val_accuracy: 0.8206\n",
      "Epoch 59/120\n",
      "782/782 [==============================] - 125s 159ms/step - loss: 0.0552 - accuracy: 0.9812 - val_loss: 0.8058 - val_accuracy: 0.8209\n",
      "Epoch 60/120\n",
      "782/782 [==============================] - 124s 159ms/step - loss: 0.0534 - accuracy: 0.9815 - val_loss: 0.8275 - val_accuracy: 0.8179\n",
      "Epoch 61/120\n",
      "782/782 [==============================] - 125s 159ms/step - loss: 0.0532 - accuracy: 0.9808 - val_loss: 0.8335 - val_accuracy: 0.8218\n",
      "Epoch 62/120\n",
      "782/782 [==============================] - 121s 154ms/step - loss: 0.0493 - accuracy: 0.9827 - val_loss: 0.8251 - val_accuracy: 0.8212\n",
      "Epoch 63/120\n",
      "782/782 [==============================] - 121s 154ms/step - loss: 0.0529 - accuracy: 0.9819 - val_loss: 0.8081 - val_accuracy: 0.8219\n",
      "Epoch 64/120\n",
      "782/782 [==============================] - 121s 154ms/step - loss: 0.0475 - accuracy: 0.9835 - val_loss: 0.8615 - val_accuracy: 0.8168\n",
      "Epoch 65/120\n",
      "782/782 [==============================] - 121s 154ms/step - loss: 0.0461 - accuracy: 0.9840 - val_loss: 0.8456 - val_accuracy: 0.8203\n",
      "Epoch 66/120\n",
      "782/782 [==============================] - 121s 154ms/step - loss: 0.0457 - accuracy: 0.9843 - val_loss: 0.8260 - val_accuracy: 0.8217\n",
      "Epoch 67/120\n",
      "782/782 [==============================] - 121s 154ms/step - loss: 0.0456 - accuracy: 0.9847 - val_loss: 0.8515 - val_accuracy: 0.8201\n",
      "Epoch 68/120\n",
      "782/782 [==============================] - 121s 154ms/step - loss: 0.0442 - accuracy: 0.9841 - val_loss: 0.8572 - val_accuracy: 0.8212\n",
      "Epoch 69/120\n",
      "782/782 [==============================] - 122s 155ms/step - loss: 0.0431 - accuracy: 0.9843 - val_loss: 0.8656 - val_accuracy: 0.8212\n",
      "Epoch 70/120\n",
      "782/782 [==============================] - 122s 156ms/step - loss: 0.0440 - accuracy: 0.9857 - val_loss: 0.8569 - val_accuracy: 0.8224\n",
      "Epoch 71/120\n",
      "782/782 [==============================] - 122s 156ms/step - loss: 0.0392 - accuracy: 0.9865 - val_loss: 0.8776 - val_accuracy: 0.8209\n",
      "Epoch 72/120\n",
      "782/782 [==============================] - 122s 157ms/step - loss: 0.0417 - accuracy: 0.9862 - val_loss: 0.8816 - val_accuracy: 0.8176\n",
      "Epoch 73/120\n",
      "782/782 [==============================] - 122s 156ms/step - loss: 0.0403 - accuracy: 0.9861 - val_loss: 0.8733 - val_accuracy: 0.8200\n",
      "Epoch 74/120\n",
      "782/782 [==============================] - 122s 156ms/step - loss: 0.0407 - accuracy: 0.9857 - val_loss: 0.8675 - val_accuracy: 0.8192\n",
      "Epoch 75/120\n",
      "782/782 [==============================] - 122s 156ms/step - loss: 0.0404 - accuracy: 0.9862 - val_loss: 0.8780 - val_accuracy: 0.8232\n",
      "Epoch 76/120\n",
      "782/782 [==============================] - 122s 156ms/step - loss: 0.0391 - accuracy: 0.9867 - val_loss: 0.8504 - val_accuracy: 0.8252\n",
      "Epoch 77/120\n",
      "782/782 [==============================] - 121s 155ms/step - loss: 0.0368 - accuracy: 0.9868 - val_loss: 0.8564 - val_accuracy: 0.8242\n",
      "Epoch 78/120\n",
      "782/782 [==============================] - 122s 157ms/step - loss: 0.0338 - accuracy: 0.9882 - val_loss: 0.8929 - val_accuracy: 0.8206\n",
      "Epoch 79/120\n",
      "782/782 [==============================] - 122s 156ms/step - loss: 0.0367 - accuracy: 0.9880 - val_loss: 0.9053 - val_accuracy: 0.8222\n",
      "Epoch 80/120\n",
      "782/782 [==============================] - 122s 157ms/step - loss: 0.0378 - accuracy: 0.9874 - val_loss: 0.8731 - val_accuracy: 0.8193\n",
      "Epoch 81/120\n",
      "782/782 [==============================] - 122s 156ms/step - loss: 0.0340 - accuracy: 0.9885 - val_loss: 0.8604 - val_accuracy: 0.8240\n",
      "Epoch 82/120\n",
      "782/782 [==============================] - 122s 156ms/step - loss: 0.0347 - accuracy: 0.9883 - val_loss: 0.8929 - val_accuracy: 0.8216\n",
      "Epoch 83/120\n",
      "782/782 [==============================] - 122s 156ms/step - loss: 0.0359 - accuracy: 0.9878 - val_loss: 0.8512 - val_accuracy: 0.8253\n",
      "Epoch 84/120\n",
      "782/782 [==============================] - 123s 157ms/step - loss: 0.0317 - accuracy: 0.9892 - val_loss: 0.8781 - val_accuracy: 0.8267\n",
      "Epoch 85/120\n",
      "782/782 [==============================] - 122s 156ms/step - loss: 0.0294 - accuracy: 0.9901 - val_loss: 0.8898 - val_accuracy: 0.8212\n",
      "Epoch 86/120\n",
      "782/782 [==============================] - 121s 154ms/step - loss: 0.0343 - accuracy: 0.9882 - val_loss: 0.9015 - val_accuracy: 0.8250\n",
      "Epoch 87/120\n",
      "782/782 [==============================] - 121s 155ms/step - loss: 0.0334 - accuracy: 0.9884 - val_loss: 0.8905 - val_accuracy: 0.8249\n",
      "Epoch 88/120\n",
      "782/782 [==============================] - 121s 155ms/step - loss: 0.0312 - accuracy: 0.9897 - val_loss: 0.8641 - val_accuracy: 0.8267\n",
      "Epoch 89/120\n",
      "782/782 [==============================] - 121s 155ms/step - loss: 0.0319 - accuracy: 0.9892 - val_loss: 0.8905 - val_accuracy: 0.8261\n",
      "Epoch 90/120\n",
      "782/782 [==============================] - 123s 157ms/step - loss: 0.0286 - accuracy: 0.9897 - val_loss: 0.8820 - val_accuracy: 0.8273\n",
      "Epoch 91/120\n",
      "782/782 [==============================] - 121s 154ms/step - loss: 0.0305 - accuracy: 0.9896 - val_loss: 0.8876 - val_accuracy: 0.8242\n",
      "Epoch 92/120\n",
      "782/782 [==============================] - 122s 155ms/step - loss: 0.0299 - accuracy: 0.9898 - val_loss: 0.8887 - val_accuracy: 0.8269\n",
      "Epoch 93/120\n",
      "782/782 [==============================] - 121s 155ms/step - loss: 0.0290 - accuracy: 0.9901 - val_loss: 0.9013 - val_accuracy: 0.8274\n",
      "Epoch 94/120\n",
      "782/782 [==============================] - 121s 155ms/step - loss: 0.0315 - accuracy: 0.9895 - val_loss: 0.9098 - val_accuracy: 0.8242\n",
      "Epoch 95/120\n",
      "782/782 [==============================] - 121s 154ms/step - loss: 0.0298 - accuracy: 0.9898 - val_loss: 0.8756 - val_accuracy: 0.8287\n",
      "Epoch 96/120\n",
      "782/782 [==============================] - 121s 154ms/step - loss: 0.0256 - accuracy: 0.9914 - val_loss: 0.9111 - val_accuracy: 0.8240\n",
      "Epoch 97/120\n",
      "782/782 [==============================] - 121s 154ms/step - loss: 0.0272 - accuracy: 0.9909 - val_loss: 0.8798 - val_accuracy: 0.8273\n",
      "Epoch 98/120\n",
      "782/782 [==============================] - 121s 155ms/step - loss: 0.0283 - accuracy: 0.9905 - val_loss: 0.8748 - val_accuracy: 0.8270\n",
      "Epoch 99/120\n",
      "782/782 [==============================] - 121s 155ms/step - loss: 0.0283 - accuracy: 0.9905 - val_loss: 0.8939 - val_accuracy: 0.8264\n",
      "Epoch 100/120\n",
      "782/782 [==============================] - 121s 155ms/step - loss: 0.0269 - accuracy: 0.9907 - val_loss: 0.9196 - val_accuracy: 0.8283\n",
      "Epoch 101/120\n",
      "782/782 [==============================] - 121s 155ms/step - loss: 0.0251 - accuracy: 0.9914 - val_loss: 0.8910 - val_accuracy: 0.8267\n",
      "Epoch 102/120\n",
      "782/782 [==============================] - 122s 156ms/step - loss: 0.0263 - accuracy: 0.9907 - val_loss: 0.9037 - val_accuracy: 0.8239\n",
      "Epoch 103/120\n",
      "782/782 [==============================] - 122s 156ms/step - loss: 0.0252 - accuracy: 0.9912 - val_loss: 0.8972 - val_accuracy: 0.8284\n",
      "Epoch 104/120\n",
      "782/782 [==============================] - 122s 156ms/step - loss: 0.0275 - accuracy: 0.9909 - val_loss: 0.8976 - val_accuracy: 0.8293\n",
      "Epoch 105/120\n",
      "782/782 [==============================] - 122s 156ms/step - loss: 0.0250 - accuracy: 0.9912 - val_loss: 0.9097 - val_accuracy: 0.8271\n",
      "Epoch 106/120\n",
      "782/782 [==============================] - 122s 156ms/step - loss: 0.0253 - accuracy: 0.9912 - val_loss: 0.8933 - val_accuracy: 0.8280\n",
      "Epoch 107/120\n",
      "782/782 [==============================] - 122s 156ms/step - loss: 0.0252 - accuracy: 0.9913 - val_loss: 0.9068 - val_accuracy: 0.8249\n",
      "Epoch 108/120\n",
      "782/782 [==============================] - 121s 155ms/step - loss: 0.0255 - accuracy: 0.9911 - val_loss: 0.9033 - val_accuracy: 0.8262\n",
      "Epoch 109/120\n",
      "782/782 [==============================] - 121s 154ms/step - loss: 0.0250 - accuracy: 0.9915 - val_loss: 0.9068 - val_accuracy: 0.8297\n",
      "Epoch 110/120\n",
      "782/782 [==============================] - 121s 155ms/step - loss: 0.0232 - accuracy: 0.9921 - val_loss: 0.8996 - val_accuracy: 0.8287\n",
      "Epoch 111/120\n",
      "782/782 [==============================] - 121s 155ms/step - loss: 0.0236 - accuracy: 0.9920 - val_loss: 0.9052 - val_accuracy: 0.8302\n",
      "Epoch 112/120\n",
      "782/782 [==============================] - 121s 155ms/step - loss: 0.0222 - accuracy: 0.9925 - val_loss: 0.9256 - val_accuracy: 0.8278\n",
      "Epoch 113/120\n",
      "782/782 [==============================] - 121s 155ms/step - loss: 0.0227 - accuracy: 0.9922 - val_loss: 0.9289 - val_accuracy: 0.8275\n",
      "Epoch 114/120\n",
      "782/782 [==============================] - 121s 155ms/step - loss: 0.0236 - accuracy: 0.9921 - val_loss: 0.9314 - val_accuracy: 0.8272\n",
      "Epoch 115/120\n",
      "782/782 [==============================] - 121s 155ms/step - loss: 0.0216 - accuracy: 0.9925 - val_loss: 0.9355 - val_accuracy: 0.8252\n",
      "Epoch 116/120\n",
      "782/782 [==============================] - 121s 155ms/step - loss: 0.0217 - accuracy: 0.9923 - val_loss: 0.9253 - val_accuracy: 0.8282\n",
      "Epoch 117/120\n",
      "782/782 [==============================] - 121s 155ms/step - loss: 0.0221 - accuracy: 0.9925 - val_loss: 0.9130 - val_accuracy: 0.8265\n",
      "Epoch 118/120\n",
      "782/782 [==============================] - 121s 155ms/step - loss: 0.0219 - accuracy: 0.9922 - val_loss: 0.9159 - val_accuracy: 0.8289\n",
      "Epoch 119/120\n",
      "782/782 [==============================] - 121s 155ms/step - loss: 0.0218 - accuracy: 0.9926 - val_loss: 0.9146 - val_accuracy: 0.8259\n",
      "Epoch 120/120\n",
      "782/782 [==============================] - 121s 155ms/step - loss: 0.0196 - accuracy: 0.9935 - val_loss: 0.9396 - val_accuracy: 0.8275\n",
      "Accuracy: 82.75%\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.constraints import MaxNorm\n",
    "from tensorflow.keras.optimizers.legacy import SGD\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "#loading\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "#normalize\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "#1h encoding\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]\n",
    "#deeper model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(32, 32, 3), activation='relu', padding='same'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1024, activation='relu', kernel_constraint=MaxNorm(3)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu', kernel_constraint=MaxNorm(3)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "#compilation\n",
    "epochs = 120\n",
    "lrate = 0.01\n",
    "decay = lrate/epochs\n",
    "sgd = SGD(learning_rate=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "model.summary()\n",
    "#fitting\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=64)\n",
    "#check acc\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "model.save('my_model_v3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4c52d2-0ae0-478f-86b3-2d6203d09d85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
